<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Highway Speed Checker</title>
  <style>
    body {
      background: #111;
      color: white;
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }
    video, canvas {
      width: 100%;
      max-width: 720px;
      border: 2px solid #4CAF50;
      border-radius: 10px;
      margin-top: 10px;
    }
    #log {
      margin-top: 15px;
      max-width: 720px;
      background: #222;
      padding: 10px;
      border-radius: 8px;
      text-align: left;
    }
  </style>
</head>
<body>
  <h1>üöó Highway Speed Checker with Number Plate</h1>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="log">üì° Initializing...</div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const log = document.getElementById('log');

    const line1 = 150, line2 = 350;
    const distance = 10; // in meters
    const vehicleTracker = {};
    let model;

    // Camera setup
    navigator.mediaDevices.getUserMedia({
      video: { width: 640, height: 480, facingMode: "environment" }
    }).then(stream => {
      video.srcObject = stream;
    }).catch(() => {
      log.innerHTML = "‚ùå Camera not accessible.";
    });

    // Load model
    cocoSsd.load().then(m => {
      model = m;
      log.innerHTML = "‚úÖ Model loaded. Waiting for vehicles...";
    });

    function getVehicleId(pred) {
      const [x, y, w, h] = pred.bbox;
      return `${Math.round(x)}-${Math.round(y)}-${Math.round(w)}-${Math.round(h)}`;
    }

    async function detectFrame() {
      if (!model) return requestAnimationFrame(detectFrame);

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Draw reference lines
      ctx.strokeStyle = "red";
      [line1, line2].forEach(y => {
        ctx.beginPath();
        ctx.moveTo(0, y);
        ctx.lineTo(canvas.width, y);
        ctx.stroke();
      });

      const predictions = await model.detect(video);
      const classes = ['car', 'truck', 'bus', 'motorcycle'];

      predictions.forEach(async (pred) => {
        if (classes.includes(pred.class) && pred.score > 0.6) {
          const [x, y, w, h] = pred.bbox;
          const centerY = y + h / 2;
          const id = getVehicleId(pred);

          ctx.strokeStyle = "lime";
          ctx.lineWidth = 2;
          ctx.strokeRect(x, y, w, h);
          ctx.fillStyle = "white";
          ctx.fillText(pred.class.toUpperCase(), x, y - 5);

          // Detect line crossing
          const track = vehicleTracker[id] || { started: false, completed: false };

          if (!track.started && centerY > line1) {
            track.startTime = performance.now();
            track.started = true;
          }

          if (track.started && !track.completed && centerY > line2) {
            track.endTime = performance.now();
            track.completed = true;

            const timeTaken = (track.endTime - track.startTime) / 1000;
            const speed = (distance / timeTaken) * 3.6;
            const overspeed = speed > 60;

            const vehicleType = pred.class.toUpperCase();
            log.innerHTML += `
              <p>${overspeed ? '‚ö†Ô∏è' : '‚úÖ'} ${vehicleType} Speed: 
              <strong style="color:${overspeed ? 'red' : 'lime'}">${speed.toFixed(2)} km/h</strong></p>`;

            // OCR in background
            const snapshot = ctx.getImageData(x, y, w, h);
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = w;
            tempCanvas.height = h;
            tempCanvas.getContext('2d').putImageData(snapshot, 0, 0);

            Tesseract.recognize(tempCanvas, 'eng').then(result => {
              const text = result.data.text.trim().replace(/\s+/g, '');
              log.innerHTML += `<p>üîç Number Plate: <strong>${text || 'N/A'}</strong></p>`;
            }).catch(() => {
              log.innerHTML += `<p style="color:orange;">‚ö†Ô∏è OCR failed</p>`;
            });
          }

          vehicleTracker[id] = track;
        }
      });

      requestAnimationFrame(detectFrame);
    }

    video.addEventListener('play', () => {
      detectFrame();
    });
  </script>
</body>
</html>
